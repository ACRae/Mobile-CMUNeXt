%----------------------------------------------------------------------------------------
%    PACKAGES AND THEMES
%----------------------------------------------------------------------------------------

\documentclass[aspectratio=169,xcolor=dvipsnames]{beamer}

\usetheme{SimpleColors}


\usepackage{hyperref}
\usepackage{graphicx} % Allows including images
\usepackage{booktabs} % Allows the use of \toprule, \midrule and \bottomrule in tables
\usepackage{subcaption}
\usepackage{tcolorbox}
\usepackage{tikz}
\usepackage{multicol}
\usepackage{multirow}
\usepackage{array}
\usepackage{pgfplots}
\pgfplotsset{compat=1.18}
\usepackage[table]{xcolor}
\usepackage{colortbl}
\usepackage{nicematrix}
\usepackage{booktabs} % optional, for better lines


\graphicspath{{./figures/}} % Figures Path
\bibliographystyle{unsrt}

\newcommand{\itemvtab}{\setlength{\itemsep}{0.3cm}}
\newcommand{\vtab}{\vspace{0.3cm}}
\NewDocumentCommand{\fittowidth}{O{\textwidth} m}{%
  \resizebox{#1}{!}{#2}%
}
\renewcommand{\arraystretch}{1.2}

%----------------------------------------------------------------------------------------
%    TITLE PAGE
%----------------------------------------------------------------------------------------

\title[Mobile-CMUNeXt]{Mobile-CMUNeXt: Semantic Segmentation of Medical Images for Fast Diagnosis}
\subtitle{CAD Presentation}

\author[António Carvalho]
{António Carvalho\inst{1}}

\institute[ISEL]
{
  \inst{1}%
    Mestrado em Engenharia Informática e de Computadores \\
    Insituto Superior de Engenharia de Lisboa
}


\date{\today}

%----------------------------------------------------------------------------------------
%    PRESENTATION SLIDES
%----------------------------------------------------------------------------------------

\begin{document}
\captionsetup{labelformat=empty, labelsep=none}


\begin{frame}
    % Print the title page as the first slide
    \titlepage
\end{frame}

\begin{frame}{Overview}
    % Throughout your presentation, if you choose to use \section{} and \subsection{} commands, these will automatically be printed on this slide as an overview of your presentation
    \tableofcontents
\end{frame}


%------------------------------------------------
\section{Introduction}
%------------------------------------------------

% Falar sobre:
% * O que é a segmentação semantica de imagems 
% * qual é o objetivo do trabalho


\begin{frame}{Introduction}
    \begin{multicols}{2}
        \begin{itemize}
            \item \textbf{Objective}: Develop a fast and efficient medical image segmentation model and implement into resource constrained devices like FPGA's.
        \end{itemize}
        
        \begin{itemize}
            \item \textbf{Semantic segmentation}: Classify image regions at the pixel level separating elements in background from elements in foreground.
        \end{itemize}
    \end{multicols}
    \vtab
    
    \begin{figure}
        \includegraphics[width=.6\textwidth]{figures/segnet_softmax.pdf}
        \caption{SegNet Overview}
    \end{figure}
    
\end{frame}


%------------------------------------------------
\section{Problem}
%------------------------------------------------

\begin{frame}{Problem}
    \begin{multicols}{2}
        \begin{enumerate}
            \item High computational cost and large memory footprint of deep learning models.
            \item Difficulty deploying complex models on resource-constrained devices.
            \item Need for faster inference speed.
            \item Automated medical imaging analysis in the healthcare sector. % pipelien from mri to image segmentation to image classification 
            \item High hardware cost for real-time inference.
            \item Healthcare privacy implications in third-party solutions. % choose local inference
        \end{enumerate}
    \end{multicols}
\end{frame}

%------------------------------------------------


%------------------------------------------------
\subsection{State of The Art}
%------------------------------------------------

% Falar sobre:
% * Origem U-Net
% * O que já esta feito - Abordagens
% * Objetivo desses projectos vs o nosso objetivo (MobileNetVX)
% * Tabela comparar modelos (reduzida) em termos de tamanho e MACS (se possivel)
% * Vantagens e desvantagens até chegar ao motivo de escolha do modelo
% * Datasets

\begin{frame}[allowframebreaks]{State of The Art}
    \begin{itemize}
        \item \textbf{U-Net}: Benchmark architecture for medical image segmentation.  
        \item \textbf{Vision Transformers}: Self-attention-based models enhancing segmentation (e.g., ViT \cite{alexey2020image}, Swin-UNet \cite{cao2022swin}). %ViT invented by google 
        \item \textbf{MLP Modules}: Efficient alternatives to self-attention, integrated into models like UNeXt \cite{chang2024unext}.  
        \item \textbf{Depthwise Separable Convolutions}: Lightweight convolutions improving efficiency (e.g., MobileNetV2 \cite{sandler2018mobilenetv2}).  
        \item \textbf{Lightweight Networks}: Compact models optimizing segmentation with minimal parameters (e.g., CFPNet-M \cite{lou2023cfpnet}).
    \end{itemize}

    \framebreak
    \begin{columns}
        \column{.45\textwidth}
        \centering
        \begin{table}[t]
            \footnotesize
            \input{tables/tab:models_comparison}
        \end{table}
    
        \column{.40\textwidth}
        \centering
        \begin{table}[t]
            \footnotesize
            \input{tables/tab:cmunext_sizes_comparison}
        \end{table}
    \end{columns}
    
    % \framebreak
    
    % \begin{columns}[t] % top alignment

    %     \column{.45\textwidth}
    %     \textbf{Existing Models:}
    %     \begin{itemize}
    %         \item Are often large and computationally expensive.
    %         \item Models like \textbf{CMUNeXt} offer high accuracy and relatively low complexity making them great for resource-constrained devices.
    %     \end{itemize}

    %     \column{.45\textwidth}
    %     \textbf{Challenges:}
    %     \begin{itemize}
    %         \item Need for smaller models without sacrificing segmentation efficacy.
    %         \item Efficient deployment on edge devices (e.g., FPGAs).
    %         \item End to end flow on edge devices.
    %     \end{itemize}
        
    % \end{columns}
\end{frame}


\begin{frame}{Datasets}
    \begin{columns}[c]
        \column{.55\textwidth}
        \begin{itemize}
            \itemvtab
            \item  \textbf{BUSI} \cite{al2020dataset}: A dataset for breast ultrasound image segmentation. 647 Training Images.
            \item \textbf{FIVES} \cite{jin2022fives}: A dataset for fibrous vascular structures in medical images. 600 Training Images and 200 Testing images.
            \item \textbf{ISIC2016} \cite{isic2016dataset}: A benchmark dataset for skin lesion segmentation. 900 Training Images and 379 Testing images
        \end{itemize}
        
        \column{.45\textwidth}

        \centering
        \begin{tabular}{ccc}
            \includegraphics[width=.3\textwidth, height=.3\textwidth]{figures/BUSI/images/benign (9).png} & 
            \includegraphics[width=.3\textwidth, height=.3\textwidth]{figures/BUSI/mask/benign (9)_mask.png} \\
            
            \includegraphics[width=.3\textwidth, height=.3\textwidth]{figures/FIVES/images/6_A.png} & 
            \includegraphics[width=.3\textwidth, height=.3\textwidth]{figures/FIVES/mask/6_A.png} \\
            
            \includegraphics[width=.3\textwidth, height=.3\textwidth]{figures/ISIC2016/images/ISIC_0000486.jpg} & 
            \includegraphics[width=.3\textwidth, height=.3\textwidth]{figures/ISIC2016/mask/ISIC_0000486_Segmentation.png} \\
        \end{tabular}
    \end{columns}
\end{frame}



%------------------------------------------------
\section{Approach}
%------------------------------------------------

% Falar sobre:
% * CMUNeXt e as configuraçõe da rede (tamanhos C, L, K), explicar (por alto) o porque da configuração final
% * Mostrar arquitetura de rede CMUNeXt
% * Optimizações feitas sobre o modelo e comparação das mesmas (GELU VS HARDSWISH ...)
% * Quantização: Brevitas, FPGA's e suporte para quanitzação
% * Extração dos pesos e "uso dos mesmos"
% * Arquitetura da rede implementada

\begin{frame}{Approach}
    \begin{columns}[c]
        \column{.45\textwidth}        
        \textbf{Environment}: Training and testing environment set up using the selected networks and datasets.
        \vtab
        
        \textbf{Criteria}:
        \begin{itemize}
            \item Performance Comparison and Architectural Analysis
            \item 5\% Tolerable Performance Degradation
            \item Reproducibility and Quality of Documentation
        \end{itemize}

        \column{.45\textwidth}
        \textbf{CMUNeXt}:
        \begin{itemize}
            \item Highly modular and adaptable architecture.
             \item Lightweight while achieving state-of-the-art results.
            \item Well-documented with reproducible experiments.
        \end{itemize}
        
    \end{columns}
\end{frame}


\begin{frame}{CMUNeXt}
    \begin{figure}
        \includegraphics[width=.9\textwidth]{figures/CMUNeXt.png}
    \end{figure}
\end{frame}


\begin{frame}{CMUNeXt - Variants}
    \begin{table}[t]
        \footnotesize
        \fittowidth{\input{tables/tab:cmunext_configs}}
        \caption{CMUNeXt Configuration Variants}
    \end{table}
\end{frame}


%------------------------------------------------
\subsection{Optimizations}
%------------------------------------------------


\begin{frame}{Overview}
    \begin{itemize}
        \itemvtab
        \item \textbf{Reduce Model Size}: Thorough testing with different configurations in order to reduce model's size and still obtain good results in semantic segmentation tasks.
        \item \textbf{Quantization}: Reduce model size and memory footprint via arbitrary precision.
        \item \textbf{Simplify Operations}: Architectural simplification by replacing concatenation operations with addition.
        \item \textbf{Activation Function}: Activation function replacement with simpler alternatives.
    \end{itemize}
\end{frame}



\begin{frame}[allowframebreaks]{Model Size}
    \begin{table}[t]
        \fittowidth{\input{tables/tab:mobile_cmunext_configs}}
        \caption{CMUNeXt Configuration Variants and Custom Configuration}
    \end{table}

    \framebreak
    \begin{columns}
        \column{.45\textwidth}
        \begin{itemize}
            \itemvtab
            \item Only \textbf{0.04M parameters} and \textbf{0.47G MACs}, it is the lightest model in the benchmark.
            \item CMUNeXt-XXS achieves \textbf{98.7\% reduction in parameters} and \textbf{93.6\% reduction in MACs} compared to the base CMUNeXt configuration.
        \end{itemize}  
        \column{.45\textwidth}
        \begin{table}[t]
            \fittowidth{\input{tables/tab:mobile_cmunext_size_comparison}}
        \caption{Model Size Comparison}
    \end{table}
    \end{columns}
    
\end{frame}



\begin{frame}[allowframebreaks]{Quantization}
    \begin{minipage}{0.58\textwidth}
        \textbf{Definition}:
        \begin{itemize}
            \item Reduces numerical precision of neural network's weights and activations by transforming floating-point values into lower-bit fixed-point representations.
        \end{itemize}
        \vtab
        \textbf{Motivation:}
        \begin{itemize}
            \item Reduces model size and memory footprint but with the cost of reduced precision.
            \item Increases inference speed, especially on hardware with limited resources.
        \end{itemize}
    \end{minipage}
    \hfill
    \begin{minipage}{0.4\textwidth}
        \begin{examples}
        \footnotesize
        \textbf{8-bit Fixed-Point (Q4.4)}
            \begin{itemize}
                \item Q4.4 format: 4 bits for integer, 4 bits for fraction
                \item Binary: \texttt{01011010}
                \item Integer part: \texttt{0101} = 5
                \item Fractional part: \texttt{1010} = 10/16 = 0.625
                \item Final value: \textbf{5.625}
            \end{itemize}
        \end{examples}
    \end{minipage}
    
    % Explicar com um exemplo claro o que é quantização e como podemos benificiar disso na FPGA
    % Treino quantizado e extração dos pesos usando brevitas
    \framebreak
    \textbf{Dynamic Quantization:}
    \begin{itemize}
        \item Applies quantization dynamically during inference.
        \item Weights are quantized on-the-fly based on the input data.
    \end{itemize}
    \vtab
    \textbf{Quantization-Aware Training (QAT):}
    \begin{itemize}
        \item Integrates quantization into the training process.
        \item Simulates quantization effects during forward and backward passes.
        \item Helps the model learn to adapt to the quantization noise resulting in better accuracy than post-training quantization.
    \end{itemize}
\end{frame}

\begin{frame}{Activation Function}
    \begin{columns}
    \column{.45\textwidth}
    \begin{itemize}
        \item $ \text{GELU}(x) = x \cdot \Phi(x) $
        \vtab
        \item $ \text{Hardswish}(x) = x \cdot \frac{\max(0, \min(1, \frac{x + 3}{6}) )}{1} $
        \vtab
        \item $ \text{ReLU}(x) = \max(0, x) $
        \vtab
        \item $\text{LeakyReLU}(x) = \begin{cases} x & \text{if } x > 0 \\ 0.1x & \text{if } x \leq 0 \end{cases}$
    \end{itemize}

    \begin{block}{Cumulative Distribution Function}
        \centering
        $ \Phi(x) = \frac{1}{2} \left( 1 + \text{erf}\left(\frac{x}{\sqrt{2}}\right) \right), \text{erf}(x) = \frac{2}{\sqrt{\pi}} \int_0^x e^{-t^2} \, dt $
    \end{block}

    \column{.45\textwidth}
        \begin{figure}
            \fittowidth{\input{figures/fig:activation_fun_comparison}}
            \caption{Activation Functions Comparison}
        \end{figure}
    \end{columns}
\end{frame}


\subsection{Architecture}

\begin{frame}{Mobile-CMUNeXt}
    \begin{figure}
        \includegraphics[width=\textwidth]{figures/Network Architecture.pdf}
    \end{figure}
\end{frame}





%------------------------------------------------
\section{Results}
%------------------------------------------------

\begin{frame}{Configuration}
    \begin{multicols}{2}
        \begin{itemize}
            \itemvtab
            \item \textbf{Hardware}: NVIDIA GeForce RTX 4080 (Driver: 535.183.01)
            \item \textbf{Frameworks}: 
            \begin{itemize}
                \item PyTorch (CUDA 11.8)
                \item Brevitas 0.11.0 \cite{brevitas}
            \end{itemize}
            
            \item \textbf{Training Conditions}:
            \begin{itemize}
                \item Epochs: 300
                \item Batch size: 8
            \end{itemize}
            \item \textbf{Input Image Size}: $256 \times 256$ pixels
            \item \textbf{Optimizer}: 
            \begin{itemize}
                \item Adam
                \item Learning rate: $1 \times 10^{-3}$
                \item Weight decay: $1 \times 10^{-4}$
            \end{itemize}
            \item \textbf{Learning Rate Scheduler}: 
            \begin{itemize}
                \item Cosine Annealing
                \item $T_{\text{max}}$: $1 \times 10^{-3}$
                \item $\eta_{\text{min}}$: $1.0 \times 10^{-5}$
            \end{itemize}
        \end{itemize}
    \end{multicols}
\end{frame}

\begin{frame}[allowframebreaks]{Metrics}
    \begin{multicols}{2}
        \begin{itemize}
            \item \textbf{IoU (Intersection over Union)}: Measures the overlap between predicted and actual positives:
            \[
            \text{IoU} = \frac{TP}{TP + FP + FN}
            \]
            
            \item \textbf{Dice}: Similarity measure between prediction and ground truth:
            \[
            \text{Dice} = \frac{2TP}{2TP + FP + FN}
            \]

            \item \textbf{SE (Sensitivity)}: True positives over all actual positives:
            \[
            \text{SE} = \frac{TP}{TP + FN}
            \]

            \item \textbf{PC (Precision)}: True positives over all predicted positives:
            \[
            \text{PC} = \frac{TP}{TP + FP}
            \]
        \end{itemize}
    \end{multicols}
    \begin{multicols}{2}
        \begin{itemize}
            \item \textbf{F1 Score}: Harmonic mean of precision and recall:
            \[
            F1 = 2 \cdot \frac{\text{Precision} \cdot \text{Recall}}{\text{Precision} + \text{Recall}}
            \]
            \vtab
            \item \textbf{Loss}: Combined binary cross-entropy and Dice loss:
            \[
            \mathcal{L} = 0.5 \cdot \text{BCE}(\hat{y}, y) + \text{Dice}(\hat{y}, y)
            \]
            \item \textbf{AAC (Average Accuracy per Class)}: Average sensitivity across all classes:
            \[
            \text{AAC} = \frac{1}{N} \sum_{i=1}^{N} \frac{TP_i}{TP_i + FN_i}
            \]
        \end{itemize}
    \end{multicols}
\end{frame}


\begin{frame}{Training Results}
    \begin{table}
        \footnotesize
        \fittowidth[.83\textwidth]{\input{tables/tab:results}}
    \end{table}
\end{frame}


\begin{frame}{Quantization Results}
    \begin{table}
        \fittowidth[.8\textwidth]{\input{tables/quantization/tab:mobile-cmunext-quant-results}}
        \caption{Mobile-CMUNeXt Quantized Results}
    \end{table}
\end{frame}


% * Meter tabela comparação (ablation study)
% * Meter tabela comaparação função ativação (quantizada e não quant)
% * Meter tabela reduzida com resultados gerais
% * Explicar metricas usadas numa maneira simplista
% * Overvew do resultados, ou seja Compared to the base CMUNeXt model (3.14M param-
% eters, 7.41G MACs), Mobile-CMUNeXt achieves a 98.7%
% reduction in parameters and 93.6% reduction in MACs
% while maintaining comparable performance across ISIC2016,
% BUSI, and FIVES datasets.
% ISIC2016: Mobile-CMUNeXt achieves an IoU of 84.94%,
% very close to CMUNeXt (84.99%) and outperforming
% CMUNeXt-S (84.87%).
% BUSI: Mobile-CMUNeXt achieves 65.81% IoU, out-
% performing CMUNeXt-S (64.12%) and coming close to
% CMUNeXt (65.84%). It also performs competitively with
% CFPNetM (67.10%), which has 19x more parameters.
% FIVES: Mobile-CMUNeXt achieves 75.00% IoU, sur-
% passing CMUNeXt (68.77%) and CMUNeXt-L (74.82%) de-
% spite being 207x smaller. The quantized version, Mobile-
% CMUNeXt-Quant, further improves to 77.44% IoU. Overall,
% Mobile-CMUNeXt proves to be an efficient alternative to the
% existing models, offering state-of-the-art segmentation perfor-
% mance while being lightweight and working for resource-
% constrained environments.



%------------------------------------------------
\section{Summary}
%------------------------------------------------


\begin{frame}{Developed Work}
    \textbf{Phases of Development}
    \begin{enumerate}
        \item Research, framework selection, and dataset preparation.
        \item Model development, experimentation, and training.
        \item Optimization through quantization and architectural enhancements.
    \end{enumerate}
    \vtab
    \textbf{Achievements}
    \begin{itemize}
        \item Successful development of Mobile-CMUNeXt.
        \item Optimized model with 0.04M parameters and reduced MACs.
        \item Competitive performance on key medical datasets.
    \end{itemize}
\end{frame}


\begin{frame}{Future Work}
    \textbf{FPGA Implementation}
    \begin{itemize}
        \item Convert the quantized model for efficient execution on FPGA hardware.
        \item FPGA-specific optimizations: Optimize memory bandwidth, reduce latency, and implement parallel processing.
        \item \textbf{End to End Flow (TODO)}
    \end{itemize}
    \vtab
    \textbf{Hardware Design}
    \begin{itemize}
        \item Select the most suitable FPGA board.
        \item Implement and test the model on FPGA, followed by real-time performance evaluations.
    \end{itemize}
\end{frame}


\begin{frame}{Source Code \& Materials}
    \centering
    \vspace{1em}
    \textbf{\Large Mobile-CMUNeXt} \\
    \vspace{0.5em}
    The project is publicly available under the MIT License (MIT). It includes: \\
    \begin{itemize}
        \centering
        \item Source code
        \item Final report
        \item Presentation slides
    \end{itemize}
    \vspace{1em}
    \textbf{Access it on GitHub:} \\
    \url{https://github.com/ACRae/Mobile-CMUNeXt}
\end{frame}



\begin{frame}[allowframebreaks]{References}
    \footnotesize
    \bibliography{bibliography}
\end{frame}

%------------------------------------------------

% \begin{frame}
%     \Huge{\centerline{\textbf{The End}}}
% \end{frame}

%------------------------------------------------



\end{document}